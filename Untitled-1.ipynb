{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements\n",
    "  1. numpy\n",
    "  2. multiprocessing\n",
    "  3. cython or cpython \n",
    "  4. pycuda\n",
    "Introduction\n",
    "  1. Nodes\n",
    "  2. Processors/Sockets\n",
    "  3. Cores\n",
    "  4. Threads\n",
    "  5. Logical processors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lscpu (Linux)\n",
    "# sysctl -n hw.ncpu (mac)(Not tested)\n",
    "# wmic cpu get caption, name, maxclockspeed, currentclockspeed, numberofcores, numberoflogicalprocessors (Windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#44FF44;\">Using multiprocessing.pool</span>\n",
    "1. pool.map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python 00_tuto.py 1\n",
    "! python 00_tuto.py 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Job numbers and reducing execution time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python 01_tuto.py 1\n",
    "! python 01_tuto.py 10\n",
    "! python 01_tuto.py 14\n",
    "! python 01_tuto.py 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using `pool.starmap`\n",
    "   \n",
    "For more than 1 argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python 02_tuto.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using `pool.apply_async`\n",
    "\n",
    "More control over the multiprocessing tasks <br>\n",
    "Assigning multiple functions in a session <br>\n",
    "Releassing the parent process for other tasksto do <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python 03_tuto.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#FFAA00;\">Using multiprocessing.Process</span>\n",
    "Let's leave this for children to play with and focus more on cool stuff<br>\n",
    "Also, multiprocessing.Process is friendly with notebooks but... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main program continues...\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Define a function to be executed by the process\n",
    "def worker_function(name):\n",
    "    print(f\"Hello, {name}!\")\n",
    "\n",
    "if __name__=='__main__':\n",
    "  # Create a multiprocessing.Process instance\n",
    "  process1 = multiprocessing.Process(target=worker_function, args=(\"Charlie the Harley\"  ,))\n",
    "  process2 = multiprocessing.Process(target=worker_function, args=(\"Sophie the trophy\"   ,))\n",
    "  process3 = multiprocessing.Process(target=worker_function, args=(\"Albert the shepherd\" ,))\n",
    "  \n",
    "  # Start the process\n",
    "  process1.start()\n",
    "  process2.start()\n",
    "  process3.start()\n",
    "\n",
    "  # Wait for the process to finish (optional)\n",
    "  print(\"Main program continues...\")\n",
    "\n",
    "  process1.join()\n",
    "  process2.join()\n",
    "  process3.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Charlie the Harley!\n",
      "Hello, Sophie the trophy!\n",
      "Hello, Albert the shepherd!\n",
      "Main program continues...\n"
     ]
    }
   ],
   "source": [
    "! python 04_tuto.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook: \n",
    "1. The kernel will kill itself (suicide) if any cell ended running and a process is alive. join all processes before ending a cell\n",
    "2. If `Process` is called directly inside the notebook, the children can't reach the casting interface (can't `print()`) but it's possible if the Process is inside a module/script that have been imported by the notebook.\n",
    "3. In any python script, `Process` and `Pool` should be called in main scope (`if __name__=='__main__':...`) because the script is called inside all processes.\n",
    "4. We can use args or kwargs arguments in `Process` to pass arguments or keyworded arguments.\n",
    "5. There is no number of processes to specify in this case so it should be manually done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PID  22140\n",
      "PID  36440\n",
      "PID  16008\n",
      "PID  34856\n",
      "PID  32824\n",
      "PID  37412\n",
      "PID  19736\n",
      "PID  11996\n",
      "PID  30428\n",
      "PID  42324\n",
      "PID  33520\n",
      "PID  6280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\smzergua\\Documents\\paris saclay\\07_Formations\\Code Club\\05_tuto.py\", line 28, in <module>\n",
      "    processes.pop(p)\n",
      "TypeError: 'Process' object cannot be interpreted as an integer\n"
     ]
    }
   ],
   "source": [
    "! python 05_tuto.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for ind,p in enumerate(processes): `<br>  \n",
    "&emsp;`if not p.is_alive():`<br>\n",
    "&emsp;&emsp;`p.close()`<br>\n",
    "&emsp;&emsp;`processes.pop(p)`<br>\n",
    "\n",
    "It's to close all the processes that have ended their jobs. This is important if you have a lot of processes >100s. There is some files created and opened and all systems have a limited amount of memory for opening files simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#FF5500;\">Sharing  memory</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
